{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Identify !, %, and %% used in cell in Google Colab."
      ],
      "metadata": {
        "id": "MJWYzJ6wGInc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuXsuYcTE_H7",
        "outputId": "b7ec0232-0f1d-4f87-b34c-087cfa1c0cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  1 16:28:45 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi #Used to run terminal commands\n",
        "!nvcc --version\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time x = sum(range(1000000)) #Affects only one line\n",
        "%cd /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU2NwFdgFWU1",
        "outputId": "f6e802c0-fa52-435d-c093-d44ad46aac2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20.7 ms, sys: 0 ns, total: 20.7 ms\n",
            "Wall time: 20.8 ms\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Affects whole cell\n",
        "\n",
        "%%writefile hello.cu\n",
        "#include <stdio.h>\n",
        "int main() {\n",
        "  printf(\"Hello CUDA\");\n",
        "\n",
        "  return 0;\n",
        "  }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avgsSoYzFjZ9",
        "outputId": "1e27f656-20a5-4825-e380-b58fc1657b01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Identify all key nvidia-smi commands with multiple options"
      ],
      "metadata": {
        "id": "n_OlmySUGpfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi #Basic GPU Information"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22siyxagFs8e",
        "outputId": "2e1c9eff-e2b5-4a26-a97a-0c67aaaf06cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  1 16:28:45 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv #Query Specific Fields\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCf_V0ryHA4b",
        "outputId": "9fb80c94-d1d7-4539-9beb-91d36ccd4cd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, memory.total [MiB], memory.used [MiB]\n",
            "Tesla T4, 15360 MiB, 0 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi pmon -c 1 #Show Running GPU Processes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaFxULBiHQNl",
        "outputId": "210a7595-d4da-4bd6-ec3f-b15cf173f9ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# gpu         pid   type     sm    mem    enc    dec    jpg    ofa    command \n",
            "# Idx           #    C/G      %      %      %      %      %      %    name \n",
            "    0          -     -      -      -      -      -      -      -    -              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=driver_version --format=csv #Driver & CUDA Version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1fl8mhIHW-r",
        "outputId": "cbb32645-60ad-496d-cfeb-40eb518429eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "driver_version\n",
            "550.54.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Debug common CUDA errors (zero output, incorrect indexing, PTX errors)"
      ],
      "metadata": {
        "id": "AO-MeGn2HgAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sum.cu\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void sum(int *a, int *b, int *c){\n",
        "  *c = *a + *b;\n",
        "};\n",
        "\n",
        "int main(void){\n",
        "  int a, b, c;\n",
        "  int *d_a, *d_b, *d_c;\n",
        "  int size = sizeof(int);\n",
        "\n",
        "  cudaMalloc((void **)&d_a, size);\n",
        "  cudaMalloc((void **)&d_b, size);\n",
        "  cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "  a = 2;\n",
        "  b = 7;\n",
        "\n",
        "  cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  sum<<<1,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "  cudaDeviceSynchronize();  // solves zero output\n",
        "\n",
        "  cudaError_t err;\n",
        "  err = cudaGetLastError();   // solves PTX errors\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Kernel launch error: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "\n",
        "  cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  printf(\"a = %d\\n\", a);\n",
        "  printf(\"b = %d\\n\", b);\n",
        "  printf(\"a + b = %d\\n\", c);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiIqskZBHlUx",
        "outputId": "2d887b25-a8cc-4e6d-d7eb-a7f98f496457"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#solves zero output\n",
        "!nvcc -arch=sm_75 sum.cu -o sum\n",
        "! ./sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT0GpstgBzOx",
        "outputId": "57e13e8b-75d5-495d-fcca-ee83eb12f8ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = 2\n",
            "b = 7\n",
            "a + b = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a CUDA C/C++ program to demonstrate GPU kernel execu'on and thread indexing.\n",
        "\n",
        "a. Launch a CUDA kernel using: 1 block and 8 threads\n",
        "\n",
        "b. Each thread must print: Hello from GPU thread <global_thread_id>\n",
        "\n",
        "c. Compute the global thread ID using: global_thread_id = blockIdx.x * blockDim.x + threadIdx.x\n",
        "\n",
        "d. Clearly separate: Host code (CPU) & Device code (GPU kernel)"
      ],
      "metadata": {
        "id": "o-knDmQsBdTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_threads.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void GPU() {\n",
        "\n",
        "    int global_thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    printf(\"Hello from GPU thread %d\\n\", global_thread_id);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    GPU<<<1, 8>>>();\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmwm8_ZJB93D",
        "outputId": "55c6c381-e9d3-4d4a-d05a-fb932a71f034"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello_threads.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello_threads.cu -o hello_threads \\\n",
        "    -arch=compute_75 -code=sm_75\n",
        "!./hello_threads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTxUxrNSCOQr",
        "outputId": "e8a3903d-48a5-489a-85da-97dfeefe2388"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from GPU thread 0\n",
            "Hello from GPU thread 1\n",
            "Hello from GPU thread 2\n",
            "Hello from GPU thread 3\n",
            "Hello from GPU thread 4\n",
            "Hello from GPU thread 5\n",
            "Hello from GPU thread 6\n",
            "Hello from GPU thread 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write a CUDA program to demonstrate host and device memory separation.\n",
        "\n",
        "a. Create an integer array of size 5 on the host (CPU).\n",
        "\n",
        "b. Allocate corresponding memory on the device (GPU) using cudaMalloc().\n",
        "\n",
        "c. Copy data from host to device using cudaMemcpy().\n",
        "\n",
        "d. Launch a kernel where GPU threads print values from device memory.\n",
        "\n",
        "e. Copy the data back from device to host and print it on CPU"
      ],
      "metadata": {
        "id": "IVn8IpwmD0Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile host_device_memory.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void printArray(int *d_arr) {\n",
        "    int id = threadIdx.x;\n",
        "    if (id < 5) {\n",
        "        printf(\"GPU thread %d: value = %d\\n\", id, d_arr[id]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int h_arr[5] = {10, 20, 30, 40, 50};\n",
        "    int *d_arr;\n",
        "    int size = 5 * sizeof(int);\n",
        "\n",
        "    cudaMalloc((void**)&d_arr, size);\n",
        "    cudaMemcpy(d_arr, h_arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    printArray<<<1, 5>>>(d_arr);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h_arr, d_arr, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"CPU: h_arr[%d] = %d\\n\", i, h_arr[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB3VFanXD9V1",
        "outputId": "243a1c85-0a9d-4264-c364-d757b71e6f07"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting host_device_memory.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc host_device_memory.cu -o host_device_memory \\\n",
        "    -gencode arch=compute_75,code=sm_75\n",
        "!./host_device_memory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB-mRLsuEZxe",
        "outputId": "3cd30e13-5015-4e9c-d106-f66972f8deb3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU thread 0: value = 10\n",
            "GPU thread 1: value = 20\n",
            "GPU thread 2: value = 30\n",
            "GPU thread 3: value = 40\n",
            "GPU thread 4: value = 50\n",
            "\n",
            "CPU: h_arr[0] = 10\n",
            "CPU: h_arr[1] = 20\n",
            "CPU: h_arr[2] = 30\n",
            "CPU: h_arr[3] = 40\n",
            "CPU: h_arr[4] = 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compare CPU 'mes of List/tuple with Numpy arrays.\n",
        "\n"
      ],
      "metadata": {
        "id": "ISi0_EkME5O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10000000\n",
        "\n",
        "lst = list(range(N))\n",
        "start = time.time()\n",
        "[x * 2 for x in lst]\n",
        "print(\"List time:\", time.time() - start)\n",
        "\n",
        "arr = np.arange(N)\n",
        "start = time.time()\n",
        "arr * 2\n",
        "print(\"NumPy array time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GoSQZYDE5jN",
        "outputId": "df0d4e2e-dd6c-4c8e-915e-adc3336e230a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List time: 0.5246992111206055\n",
            "NumPy array time: 0.024084806442260742\n"
          ]
        }
      ]
    }
  ]
}